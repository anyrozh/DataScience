# -*- coding: utf-8 -*-
"""matching.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/146m-RUoNctCsUJdU8ozFYUNf7ve3lhWE

Нас попросили разработать алгоритм, **который вычисляет вероятность того, что пользователь с месячной подпиской не продлит подписку в следующем месяце.**

1. products.csv — файл с информацией о товарах.

2. product_pairs.csv — файл с парами похожих товаров.

На этом шаге **Вы должны реализовать алгоритм**, который находит пары товаров с **максимальным реколлом при ограничении на количество кандидатов (максимум X пар)**.

1. **Максимизировать реколл** – найти как можно больше правильных пар товаров.

2. **Отсев лишнего** – ограничить общее количество пар, не более чем Х.

**Cхожесть имен и описаний**
"""

import itertools
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

def get_common_attributes(product1, product2):
    """
    Возвращает список общих атрибутов двух товаров, включая схожесть их имен и описаний.

    Аргументы:
    - product1: словарь, представляющий первый товар с его атрибутами.
    - product2: словарь, представляющий второй товар с его атрибутами.

    Возвращает:
    - common_attributes: список общих атрибутов, включая 'name' и 'description', если схожесть больше порога.
    """
    common_attributes = []

    # Список атрибутов, которые мы сравниваем
    attributes_to_compare = ['brand', 'category', 'size']

    # Проверяем каждый атрибут

    '''YOUR CODE HERE'''
    for attr in attributes_to_compare:
      if product1.get(attr) == product2.get(attr):
        common_attributes.append(attr)

    # Векторизация имен товаров

    #Далее этот список из двух названий товаров отправляют в TfidfVectorizer, чтобы посчитать насколько похожи названия товаров между собой.
    names = [str(product1.get('name',"")),str(product2.get('name',""))]
    vectorizer_name = TfidfVectorizer().fit(names)
    tfidf_matrix_name = vectorizer_name.transform(names)

    # Вычисление косинусного сходства между именами товаровм -> между первым и вторым
    # первое и второе слова
    similarity_name = cosine_similarity(tfidf_matrix_name[0],tfidf_matrix_name[1])[0][0]

    # Если сходство имен больше определенного порога, добавляем имя в общие атрибуты
    if similarity_name > 0.5:
      common_attributes.append('name')
    return common_attributes

    # Векторизация описаний товаров
    description = [str(product1.get('name',"")),str(product2.get('name',""))]
    vectorizer_description = TfidfVectorizer().fit(description)
    tfidf_matrix_description = vectorizer_name.transform(description)

    # Вычисление косинусного сходства между описаниями товаров
    similarity_description = cosine_similarity(tfidf_matrix_description[0],tfidf_matrix_description[1])[0][0]

    # Если сходство описаний больше определенного порога, добавляем описание в общие атрибуты
    if similarity_description > 0.5:
        '''
        YOUR CODE HERE
        '''
        сommon_atrributes.append('description')

    return common_attributes

"""**generate_candidates**

Напишите функцию generate_candidates, которая **генерирует возможные пары товаров, имеющих не менее двух общих атрибутов**. Функция должна принимать на вход список словарей, где каждый словарь представляет собой товар с определенными атрибутами. Каждая пара товаров, удовлетворяющая условию, должна быть представлена в виде кортежа, содержащего идентификаторы двух товаров и их общие атрибуты. Результат функции — список таких кортежей:
"""

def generate_candidates(products):
    """
    Генерирует список кандидатов из пар продуктов, которые имеют не менее двух общих атрибутов.

    Аргументы:
    - products: список словарей, где каждый словарь представляет собой продукт с определенными атрибутами.

    Возвращает:
    - candidates: список кортежей, где каждый кортеж содержит идентификаторы двух продуктов и их общие атрибуты.
    """
    candidates = []
    n = len(products)
    for i, product1 in enumerate(products):
      product1 = products[i]
      for j in range(i + 1, n):
            '''
            YOUR CODE HERE
            '''
            product2 = products[j]
            common_attrs = get_common_attributes(product1,product2)
            if len(common_attrs) >= 2:
              candidates.append((product1['id'],product2['id'],common_attrs))
    return candidates

def get_best_candidates(candidates, X):
    """
    Сортирует пары товаров по количеству общих атрибутов и возвращает X лучших пар.

    Аргументы:
    - candidates: Список пар товаров [(product1_id, product2_id, общие атрибуты), ...]
    - X: Количество лучших пар, которые нужно вернуть

    Возвращает:
    - Список лучших X пар товаров, отсортированных по количеству общих атрибутов
    """
    candidates = sorted(candidates, key=lambda item: len(item[2]), reverse=True)
    return candidates[:X]

import itertools
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

def get_common_attributes(product1, product2):
    """
    Возвращает список общих атрибутов двух товаров, включая схожесть их имен и описаний.

    Аргументы:
    - product1: словарь, представляющий первый товар с его атрибутами.
    - product2: словарь, представляющий второй товар с его атрибутами.

    Возвращает:
    - common_attributes: список общих атрибутов, включая 'name' и 'description', если схожесть больше порога.
    """
    common_attributes = []

    # Список атрибутов, которые мы сравниваем
    attributes_to_compare = ['brand', 'category', 'size']

    # Проверяем каждый атрибут

    '''YOUR CODE HERE'''
    for attr in attributes_to_compare:
      if product1.get(attr) == product2.get(attr):
        common_attributes.append(attr)

    # Векторизация имен товаров

    #Далее этот список из двух названий товаров отправляют в TfidfVectorizer, чтобы посчитать насколько похожи названия товаров между собой.
    names = [str(product1.get('name',"")),str(product2.get('name',""))]
    vectorizer_name = TfidfVectorizer().fit(names)
    tfidf_matrix_name = vectorizer_name.transform(names)

    # Вычисление косинусного сходства между именами товаровм -> между первым и вторым
    # первое и второе слова
    similarity_name = cosine_similarity(tfidf_matrix_name[0],tfidf_matrix_name[1])[0][0]

    # Если сходство имен больше определенного порога, добавляем имя в общие атрибуты
    if similarity_name > 0.5:
      common_attributes.append('name')
    return common_attributes

    # Векторизация описаний товаров
    description = [str(product1.get('name',"")),str(product2.get('name',""))]
    vectorizer_description = TfidfVectorizer().fit(description)
    tfidf_matrix_description = vectorizer_name.transform(description)

    # Вычисление косинусного сходства между описаниями товаров
    similarity_description = cosine_similarity(tfidf_matrix_description[0],tfidf_matrix_description[1])[0][0]

    # Если сходство описаний больше определенного порога, добавляем описание в общие атрибуты
    if similarity_description > 0.5:
        '''
        YOUR CODE HERE
        '''
        сommon_atrributes.append('description')

    return common_attributes

def generate_candidates(products):
    """
    Генерирует список кандидатов из пар продуктов, которые имеют не менее двух общих атрибутов.

    Аргументы:
    - products: список словарей, где каждый словарь представляет собой продукт с определенными атрибутами.

    Возвращает:
    - candidates: список кортежей, где каждый кортеж содержит идентификаторы двух продуктов и их общие атрибуты.
    """
    candidates = []
    n = len(products)
    for i, product1 in enumerate(products):
      product1 = products[i]
      for j in range(i + 1, n):
            '''
            YOUR CODE HERE
            '''
            product2 = products[j]
            common_attrs = get_common_attributes(product1,product2)
            if len(common_attrs) >= 2:
              candidates.append((product1['id'],product2['id'],common_attrs))
    return candidates

def get_best_candidates(candidates, X):
    """
    Сортирует пары товаров по количеству общих атрибутов и возвращает X лучших пар.

    Аргументы:
    - candidates: Список пар товаров [(product1_id, product2_id, общие атрибуты), ...]
    - X: Количество лучших пар, которые нужно вернуть

    Возвращает:
    - Список лучших X пар товаров, отсортированных по количеству общих атрибутов
    """
    candidates = sorted(candidates, key=lambda item: len(item[2]), reverse=True)
    return candidates[:X]

products = [
    {'id': 1, 'brand': 'Apple', 'size': '6.1"', 'color': 'Black', 'material': 'Glass', 'category': 'Smartphones', 'name': 'iPhone 13', 'description': 'iPhone 13 with A15 chip'},
    {'id': 2, 'brand': 'Apple', 'size': '6.1"', 'color': 'White', 'material': 'Glass', 'category': 'Smartphones', 'name': 'iPhone 13 mini', 'description': 'Smaller iPhone 13 with same power'},
    {'id': 3, 'brand': 'Samsung', 'size': '6.2"', 'color': 'Black', 'material': 'Plastic', 'category': 'Smartphones', 'name': 'Samsung Galaxy S21', 'description': 'Galaxy S21 with amazing camera'}
]

# Генерация кандидатов
candidates = generate_candidates(products)

# Выбор лучших кандидатов
best_candidates = get_best_candidates(candidates, 2)

for candidate in best_candidates:
    print(f'Product1 ID: {candidate[0]}, Product2 ID: {candidate[1]}, Common Attributes: {candidate[2]}')

# Product1 ID: 1, Product2 ID: 2, Common Attributes: ['brand', 'category', 'size', 'name']

"""**Максимизировать precision** — уменьшить количество неверных рекомендаций (ложных срабатываний).
Гарантировать, что **recall не меньше X%** — минимально допустимый уровень реколла (например, не менее 70%).
"""

def recall_at_k(true_pairs, predicted_pairs):
    """
    Вычисляет recall: долю истинных пар, найденных среди предсказанных.
    true_pairs, predicted_pairs — списки кортежей (id1, id2), либо любые hashable объекты.
    """
    # Приведём к set для ускорения проверки принадлежности
    set_true = set(tuple(sorted(pair)) for pair in true_pairs)
    set_pred = set(tuple(sorted(pair)) for pair in predicted_pairs)
    true_positive = len(set_true & set_pred)
    if not true_pairs:
        return 0.0
    return true_positive / len(set_true)

def get_candidates_with_min_recall(candidates, true_pairs, min_recall):
    """
    Отбирает минимально необходимое число кандидатов для достижения min_recall.
    candidates — список кортежей (id1, id2, ...), совместимых с true_pairs по формату.
    true_pairs — список "правильных" пар (id1, id2).
    min_recall — float, например, 0.7 (70%)
    Возвращает: список выбранных кандидатов (той же структуры, что и во входе).
    """
    selected_candidates = []
    predicted_pairs = []  # Только первые 2 id, так как третье — список атрибутов
    for candidate in candidates:
        predicted_pair = tuple(sorted(candidate[:2]))  # ключ из (id1, id2)
        selected_candidates.append(candidate)
        predicted_pairs.append(predicted_pair)
        current_recall = recall_at_k(true_pairs, predicted_pairs)
        if current_recall >= min_recall:
            break
    return selected_candidates

"""Поэтому важно заранее выделять те пары, которые можно с высокой степенью уверенности считать точными матчами, и те, что требуют дополнительной проверки. **Бутстрепнутый реколл (LCB) позволяет нам не только повысить точность, но и оценость достоверность предсказаний с учётом возможных погрешностей.**

**Bootstrapped Recall** — это оценка recall, полученная с использованием бутстреп-метода. Она позволяет получить распределение значений recall и оценить его статистическую значимость.

**Lower Confidence Bound (LCB)** — это нижняя граница доверительного интервала. Она представляет собой наименьшее значение, которое с заданной вероятностью содержит истинное значение параметра.

**bootstrap_recall**
"""

import random

def bootstrap_recall(true_pairs, predicted_pairs, n_bootstrap=1000, alpha=0.05):
    """
    Вычисляет бутстрепнутый реколл (Lower Confidence Bound, LCB) для заданных истинных и предсказанных пар.

    Аргументы:
    - true_pairs: список истинных пар.
    - predicted_pairs: список предсказанных пар.
    - n_bootstrap: количество итераций бутстрепа.
    - alpha: уровень значимости для расчета LCB.

    Возвращает:
    - lower_bound: нижняя граница доверительного интервала реколла.
    """
    recalls = []
    random.seed(random_seed)

    true_pairs_set = set(tuple(sorted(pair)) for pair in true_pairs)
    pred_pairs_set = set(tuple(sorted(pair)) for pair in predicted_pairs)
    n_true = len(true_pairs)

    if n_true == 0:
        return 0.0
    true_pairs_list = list(true_pairs_set)

    for _ in range(n_bootstrap):
      sampled_true = [random.choice(true_pairs_list) for _ in range(n_true)]
      n_found = sum(pair in pred_pairs_set for pair in sampled_true)
      recall = n_true/n_found
      recalls.append(recall)
    recalls.sort()
    rank = max(0, min(rank, n_bootstrap - 1))
    lower_bound = recalls[rank]
    return lower_bound

def classify_pairs(true_pairs, predicted_pairs, n_bootstrap=1000, alpha=0.05):
    """
    Классифицирует предсказанные пары на две группы: "точно мэтч" (>0.95), "на валидацию" (>0.85, ≤0.95).
    - true_pairs: список кортежей (id1, id2), настоящее совпадение.
    - predicted_pairs: список кортежей (id1, id2), ваши предсказания.
    Возвращает:
    - matched_pairs: список пар >0.95
    - validation_pairs: >0.85 и ≤0.95
    """
    matched_pairs = []
    validation_pairs = []
    for pair in predicted_pairs:
        lcb_recall = bootstrap_recall(true_pairs, [pair], n_bootstrap=n_bootstrap, alpha=alpha)
        if lcb_recall > 0.95:
            matched_pairs.append(pair)
        elif lcb_recall > 0.85:
            validation_pairs.append(pair)
    return matched_pairs, validation_pairs