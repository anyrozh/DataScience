{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Tuple, Union\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "\n",
        "class Encoder:\n",
        "    \"\"\"\n",
        "    Encoder class for generating embeddings from textual data using a SentenceTransformer model.\n",
        "    \"\"\"\n",
        "    def __init__(self, model_name: str = 'cointegrated/rubert-tiny2', use_gpu: bool = False):\n",
        "        \"\"\"\n",
        "        Initializes the Encoder with the given model name and device configuration.\n",
        "        \"\"\"\n",
        "        if not model_name:\n",
        "            raise ValueError(\"Model name cannot be empty.\")\n",
        "\n",
        "        try:\n",
        "            self.device = 'cuda' if (use_gpu and torch.cuda.is_available()) else 'cpu'\n",
        "            self.model = SentenceTransformer(model_name, device=self.device)\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Failed to load model '{model_name}': {str(e)}\")\n",
        "\n",
        "    def encode(self, data: Union[List[str], str]) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Encodes text(s) into embeddings.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if isinstance(data, str):\n",
        "                data = [data]\n",
        "            embeddings = self.model.encode(data, convert_to_tensor=True, device=self.device)\n",
        "            return embeddings\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Encoding failed: {str(e)}\")\n",
        "\n",
        "class RAG:\n",
        "    \"\"\"\n",
        "    Retrieval-Augmented Generation (RAG) class.\n",
        "    \"\"\"\n",
        "    def __init__(self, encoder: Encoder):\n",
        "        \"\"\"\n",
        "        Initializes the RAG class with the given encoder.\n",
        "        \"\"\"\n",
        "        if not isinstance(encoder, Encoder):\n",
        "            raise ValueError(\"The encoder must be an instance of Encoder.\")\n",
        "        self.encoder = encoder\n",
        "        self.documents = []\n",
        "        self.doc_embeddings = None\n",
        "\n",
        "    def fit(self, documents: List[str]):\n",
        "        \"\"\"\n",
        "        Encodes and stores document embeddings.\n",
        "        \"\"\"\n",
        "        if not documents:\n",
        "            raise ValueError(\"Document list cannot be empty.\")\n",
        "        self.documents = documents\n",
        "        try:\n",
        "            self.doc_embeddings = self.encoder.encode(documents)\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Document encoding failed: {str(e)}\")\n",
        "\n",
        "    def retrieve(self, query: str, retrieval_limit: int = 5, similarity_threshold: float = 0.5) -> Tuple[List[int], List[str]]:\n",
        "        \"\"\"\n",
        "        Retrieves top-k most relevant documents for the query.\n",
        "        \"\"\"\n",
        "        if self.doc_embeddings is None:\n",
        "            raise ValueError(\"You must call fit() before retrieve().\")\n",
        "        if not (1 <= retrieval_limit <= 10):\n",
        "            raise ValueError(\"retrieval_limit must be between 1 and 10.\")\n",
        "        if retrieval_limit > len(self.documents):\n",
        "            raise ValueError(\"retrieval_limit cannot exceed number of documents.\")\n",
        "        if not (0.0 <= similarity_threshold <= 1.0):\n",
        "            raise ValueError(\"similarity_threshold must be between 0 and 1.\")\n",
        "\n",
        "        try:\n",
        "            #Кодирование запроса в вектор\n",
        "            query_embedding = self.encoder.encode(query)\n",
        "            #Расчёт косинусной схожести - как logit\n",
        "            cosine_scores = util.cos_sim(query_embedding, self.doc_embeddings)[0]  # shape: (num_docs)\n",
        "            #Выбор топ-N документов\n",
        "            top_results = torch.topk(cosine_scores, k=retrieval_limit)\n",
        "\n",
        "            relevant_indices = top_results.indices.tolist()\n",
        "            relevant_scores = top_results.values.tolist()\n",
        "\n",
        "            filtered_indices = [\n",
        "                idx for idx, score in zip(relevant_indices, relevant_scores)\n",
        "                if score >= similarity_threshold\n",
        "            ]\n",
        "\n",
        "            retrieved_docs = [self.documents[idx] for idx in filtered_indices]\n",
        "            return filtered_indices, retrieved_docs\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Retrieval failed: {str(e)}\")\n",
        "\n",
        "    def _create_prompt_template(self, query: str, retrieved_docs: List[str]) -> str:\n",
        "        \"\"\"\n",
        "        Creates a prompt template for generation.\n",
        "        \"\"\"\n",
        "\n",
        "        prompt = \"Instructions: Based on the relevant documents, generate a comprehensive response to the user's query.\\n\\n\"\n",
        "        prompt += \"Relevant Documents:\\n\"\n",
        "        for i, doc in enumerate(retrieved_docs):\n",
        "            prompt += f\"Document {i+1}: {doc}\\n\"\n",
        "        prompt += f\"\\nUser Query: {query}\\n\"\n",
        "        prompt += \"Answer:\"\n",
        "        return prompt\n",
        "\n",
        "    def _generate(self, query: str, retrieved_docs: List[str]) -> str:\n",
        "        \"\"\"\n",
        "        Placeholder for text generation logic.\n",
        "        \"\"\"\n",
        "        prompt = self._create_prompt_template(query, retrieved_docs)\n",
        "\n",
        "        generated_response = f\"(Simulated Response based on documents and query: '{query}')\"\n",
        "        return generated_response\n",
        "\n",
        "    def run(self, query: str) -> str:\n",
        "        \"\"\"\n",
        "        Runs full RAG pipeline.\n",
        "        \"\"\"\n",
        "        _, retrieved_docs = self.retrieve(query)\n",
        "        return self._generate(query, retrieved_docs)"
      ],
      "metadata": {
        "id": "brre-14gYVe7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [\n",
        "    \"Machine learning is a method of data analysis that automates analytical model building.\",\n",
        "    \"Artificial intelligence is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans.\",\n",
        "    \"Natural language processing is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language.\",\n",
        "    \"Deep learning is a class of machine learning algorithms that uses multiple layers to progressively extract higher-level features from the raw input.\"\n",
        "]\n",
        "\n",
        "encoder = Encoder()\n",
        "rag = RAG(encoder)\n",
        "rag.fit(documents)\n",
        "\n",
        "query = \"Tell me about deep learning.\"\n",
        "result_indices, result_documents  = rag.retrieve(query, retrieval_limit=2, similarity_threshold=0.6)\n",
        "\n",
        "print(f'Result indices: {result_indices}')\n",
        "print(f'Result documents: {result_documents}')\n",
        "\n",
        "# >> Output:\n",
        "# >> Result indices: [3, 0]\n",
        "# >> Result documents:\n",
        "# >> >> 'Deep learning is a class of machine learning algorithms that uses multiple layers to progressively extract higher-level features from the raw input.',\n",
        "# >> >> 'Machine learning is a method of data analysis that automates analytical model building.'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzY1LlXplzrU",
        "outputId": "6632d2fe-5c4a-4226-c2e3-254a89d873be"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result indices: [3, 0]\n",
            "Result documents: ['Deep learning is a class of machine learning algorithms that uses multiple layers to progressively extract higher-level features from the raw input.', 'Machine learning is a method of data analysis that automates analytical model building.']\n"
          ]
        }
      ]
    }
  ]
}