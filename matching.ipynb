{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Нас попросили разработать алгоритм, **который вычисляет вероятность того, что пользователь с месячной подпиской не продлит подписку в следующем месяце.**\n",
        "\n",
        "1. products.csv — файл с информацией о товарах.\n",
        "\n",
        "2. product_pairs.csv — файл с парами похожих товаров.\n",
        "\n",
        "На этом шаге **Вы должны реализовать алгоритм**, который находит пары товаров с **максимальным реколлом при ограничении на количество кандидатов (максимум X пар)**.\n",
        "\n",
        "1. **Максимизировать реколл** – найти как можно больше правильных пар товаров.\n",
        "\n",
        "2. **Отсев лишнего** – ограничить общее количество пар, не более чем Х.\n",
        "\n",
        "**Cхожесть имен и описаний**"
      ],
      "metadata": {
        "id": "KkDQBtJAGNCv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def get_common_attributes(product1, product2):\n",
        "    \"\"\"\n",
        "    Возвращает список общих атрибутов двух товаров, включая схожесть их имен и описаний.\n",
        "\n",
        "    Аргументы:\n",
        "    - product1: словарь, представляющий первый товар с его атрибутами.\n",
        "    - product2: словарь, представляющий второй товар с его атрибутами.\n",
        "\n",
        "    Возвращает:\n",
        "    - common_attributes: список общих атрибутов, включая 'name' и 'description', если схожесть больше порога.\n",
        "    \"\"\"\n",
        "    common_attributes = []\n",
        "\n",
        "    # Список атрибутов, которые мы сравниваем\n",
        "    attributes_to_compare = ['brand', 'category', 'size']\n",
        "\n",
        "    # Проверяем каждый атрибут\n",
        "\n",
        "    '''YOUR CODE HERE'''\n",
        "    for attr in attributes_to_compare:\n",
        "      if product1.get(attr) == product2.get(attr):\n",
        "        common_attributes.append(attr)\n",
        "\n",
        "    # Векторизация имен товаров\n",
        "\n",
        "    #Далее этот список из двух названий товаров отправляют в TfidfVectorizer, чтобы посчитать насколько похожи названия товаров между собой.\n",
        "    names = [str(product1.get('name',\"\")),str(product2.get('name',\"\"))]\n",
        "    vectorizer_name = TfidfVectorizer().fit(names)\n",
        "    tfidf_matrix_name = vectorizer_name.transform(names)\n",
        "\n",
        "    # Вычисление косинусного сходства между именами товаровм -> между первым и вторым\n",
        "    # первое и второе слова\n",
        "    similarity_name = cosine_similarity(tfidf_matrix_name[0],tfidf_matrix_name[1])[0][0]\n",
        "\n",
        "    # Если сходство имен больше определенного порога, добавляем имя в общие атрибуты\n",
        "    if similarity_name > 0.5:\n",
        "      common_attributes.append('name')\n",
        "    return common_attributes\n",
        "\n",
        "    # Векторизация описаний товаров\n",
        "    description = [str(product1.get('name',\"\")),str(product2.get('name',\"\"))]\n",
        "    vectorizer_description = TfidfVectorizer().fit(description)\n",
        "    tfidf_matrix_description = vectorizer_name.transform(description)\n",
        "\n",
        "    # Вычисление косинусного сходства между описаниями товаров\n",
        "    similarity_description = cosine_similarity(tfidf_matrix_description[0],tfidf_matrix_description[1])[0][0]\n",
        "\n",
        "    # Если сходство описаний больше определенного порога, добавляем описание в общие атрибуты\n",
        "    if similarity_description > 0.5:\n",
        "        '''\n",
        "        YOUR CODE HERE\n",
        "        '''\n",
        "        сommon_atrributes.append('description')\n",
        "\n",
        "    return common_attributes"
      ],
      "metadata": {
        "id": "ADuKYAf7IpOR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**generate_candidates**\n",
        "\n",
        "Напишите функцию generate_candidates, которая **генерирует возможные пары товаров, имеющих не менее двух общих атрибутов**. Функция должна принимать на вход список словарей, где каждый словарь представляет собой товар с определенными атрибутами. Каждая пара товаров, удовлетворяющая условию, должна быть представлена в виде кортежа, содержащего идентификаторы двух товаров и их общие атрибуты. Результат функции — список таких кортежей:"
      ],
      "metadata": {
        "id": "kFCGleAzStdY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_candidates(products):\n",
        "    \"\"\"\n",
        "    Генерирует список кандидатов из пар продуктов, которые имеют не менее двух общих атрибутов.\n",
        "\n",
        "    Аргументы:\n",
        "    - products: список словарей, где каждый словарь представляет собой продукт с определенными атрибутами.\n",
        "\n",
        "    Возвращает:\n",
        "    - candidates: список кортежей, где каждый кортеж содержит идентификаторы двух продуктов и их общие атрибуты.\n",
        "    \"\"\"\n",
        "    candidates = []\n",
        "    n = len(products)\n",
        "    for i, product1 in enumerate(products):\n",
        "      product1 = products[i]\n",
        "      for j in range(i + 1, n):\n",
        "            '''\n",
        "            YOUR CODE HERE\n",
        "            '''\n",
        "            product2 = products[j]\n",
        "            common_attrs = get_common_attributes(product1,product2)\n",
        "            if len(common_attrs) >= 2:\n",
        "              candidates.append((product1['id'],product2['id'],common_attrs))\n",
        "    return candidates"
      ],
      "metadata": {
        "id": "J4Fkab36SPCo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_best_candidates(candidates, X):\n",
        "    \"\"\"\n",
        "    Сортирует пары товаров по количеству общих атрибутов и возвращает X лучших пар.\n",
        "\n",
        "    Аргументы:\n",
        "    - candidates: Список пар товаров [(product1_id, product2_id, общие атрибуты), ...]\n",
        "    - X: Количество лучших пар, которые нужно вернуть\n",
        "\n",
        "    Возвращает:\n",
        "    - Список лучших X пар товаров, отсортированных по количеству общих атрибутов\n",
        "    \"\"\"\n",
        "    candidates = sorted(candidates, key=lambda item: len(item[2]), reverse=True)\n",
        "    return candidates[:X]"
      ],
      "metadata": {
        "id": "YZ_YTm8YXEfH"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def get_common_attributes(product1, product2):\n",
        "    \"\"\"\n",
        "    Возвращает список общих атрибутов двух товаров, включая схожесть их имен и описаний.\n",
        "\n",
        "    Аргументы:\n",
        "    - product1: словарь, представляющий первый товар с его атрибутами.\n",
        "    - product2: словарь, представляющий второй товар с его атрибутами.\n",
        "\n",
        "    Возвращает:\n",
        "    - common_attributes: список общих атрибутов, включая 'name' и 'description', если схожесть больше порога.\n",
        "    \"\"\"\n",
        "    common_attributes = []\n",
        "\n",
        "    # Список атрибутов, которые мы сравниваем\n",
        "    attributes_to_compare = ['brand', 'category', 'size']\n",
        "\n",
        "    # Проверяем каждый атрибут\n",
        "\n",
        "    '''YOUR CODE HERE'''\n",
        "    for attr in attributes_to_compare:\n",
        "      if product1.get(attr) == product2.get(attr):\n",
        "        common_attributes.append(attr)\n",
        "\n",
        "    # Векторизация имен товаров\n",
        "\n",
        "    #Далее этот список из двух названий товаров отправляют в TfidfVectorizer, чтобы посчитать насколько похожи названия товаров между собой.\n",
        "    names = [str(product1.get('name',\"\")),str(product2.get('name',\"\"))]\n",
        "    vectorizer_name = TfidfVectorizer().fit(names)\n",
        "    tfidf_matrix_name = vectorizer_name.transform(names)\n",
        "\n",
        "    # Вычисление косинусного сходства между именами товаровм -> между первым и вторым\n",
        "    # первое и второе слова\n",
        "    similarity_name = cosine_similarity(tfidf_matrix_name[0],tfidf_matrix_name[1])[0][0]\n",
        "\n",
        "    # Если сходство имен больше определенного порога, добавляем имя в общие атрибуты\n",
        "    if similarity_name > 0.5:\n",
        "      common_attributes.append('name')\n",
        "    return common_attributes\n",
        "\n",
        "    # Векторизация описаний товаров\n",
        "    description = [str(product1.get('name',\"\")),str(product2.get('name',\"\"))]\n",
        "    vectorizer_description = TfidfVectorizer().fit(description)\n",
        "    tfidf_matrix_description = vectorizer_name.transform(description)\n",
        "\n",
        "    # Вычисление косинусного сходства между описаниями товаров\n",
        "    similarity_description = cosine_similarity(tfidf_matrix_description[0],tfidf_matrix_description[1])[0][0]\n",
        "\n",
        "    # Если сходство описаний больше определенного порога, добавляем описание в общие атрибуты\n",
        "    if similarity_description > 0.5:\n",
        "        '''\n",
        "        YOUR CODE HERE\n",
        "        '''\n",
        "        сommon_atrributes.append('description')\n",
        "\n",
        "    return common_attributes\n",
        "\n",
        "def generate_candidates(products):\n",
        "    \"\"\"\n",
        "    Генерирует список кандидатов из пар продуктов, которые имеют не менее двух общих атрибутов.\n",
        "\n",
        "    Аргументы:\n",
        "    - products: список словарей, где каждый словарь представляет собой продукт с определенными атрибутами.\n",
        "\n",
        "    Возвращает:\n",
        "    - candidates: список кортежей, где каждый кортеж содержит идентификаторы двух продуктов и их общие атрибуты.\n",
        "    \"\"\"\n",
        "    candidates = []\n",
        "    n = len(products)\n",
        "    for i, product1 in enumerate(products):\n",
        "      product1 = products[i]\n",
        "      for j in range(i + 1, n):\n",
        "            '''\n",
        "            YOUR CODE HERE\n",
        "            '''\n",
        "            product2 = products[j]\n",
        "            common_attrs = get_common_attributes(product1,product2)\n",
        "            if len(common_attrs) >= 2:\n",
        "              candidates.append((product1['id'],product2['id'],common_attrs))\n",
        "    return candidates\n",
        "\n",
        "def get_best_candidates(candidates, X):\n",
        "    \"\"\"\n",
        "    Сортирует пары товаров по количеству общих атрибутов и возвращает X лучших пар.\n",
        "\n",
        "    Аргументы:\n",
        "    - candidates: Список пар товаров [(product1_id, product2_id, общие атрибуты), ...]\n",
        "    - X: Количество лучших пар, которые нужно вернуть\n",
        "\n",
        "    Возвращает:\n",
        "    - Список лучших X пар товаров, отсортированных по количеству общих атрибутов\n",
        "    \"\"\"\n",
        "    candidates = sorted(candidates, key=lambda item: len(item[2]), reverse=True)\n",
        "    return candidates[:X]"
      ],
      "metadata": {
        "id": "NVSEWsK4Yvpu"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "products = [\n",
        "    {'id': 1, 'brand': 'Apple', 'size': '6.1\"', 'color': 'Black', 'material': 'Glass', 'category': 'Smartphones', 'name': 'iPhone 13', 'description': 'iPhone 13 with A15 chip'},\n",
        "    {'id': 2, 'brand': 'Apple', 'size': '6.1\"', 'color': 'White', 'material': 'Glass', 'category': 'Smartphones', 'name': 'iPhone 13 mini', 'description': 'Smaller iPhone 13 with same power'},\n",
        "    {'id': 3, 'brand': 'Samsung', 'size': '6.2\"', 'color': 'Black', 'material': 'Plastic', 'category': 'Smartphones', 'name': 'Samsung Galaxy S21', 'description': 'Galaxy S21 with amazing camera'}\n",
        "]\n",
        "\n",
        "# Генерация кандидатов\n",
        "candidates = generate_candidates(products)\n",
        "\n",
        "# Выбор лучших кандидатов\n",
        "best_candidates = get_best_candidates(candidates, 2)\n",
        "\n",
        "for candidate in best_candidates:\n",
        "    print(f'Product1 ID: {candidate[0]}, Product2 ID: {candidate[1]}, Common Attributes: {candidate[2]}')\n",
        "\n",
        "# Product1 ID: 1, Product2 ID: 2, Common Attributes: ['brand', 'category', 'size', 'name']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11Hb_5teV716",
        "outputId": "51592211-6e36-4c74-e366-5292a9bf6141"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Product1 ID: 1, Product2 ID: 2, Common Attributes: ['brand', 'category', 'size', 'name']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Максимизировать precision** — уменьшить количество неверных рекомендаций (ложных срабатываний).\n",
        "Гарантировать, что **recall не меньше X%** — минимально допустимый уровень реколла (например, не менее 70%)."
      ],
      "metadata": {
        "id": "3KqSrBSehSoj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recall_at_k(true_pairs, predicted_pairs):\n",
        "    \"\"\"\n",
        "    Вычисляет recall: долю истинных пар, найденных среди предсказанных.\n",
        "    true_pairs, predicted_pairs — списки кортежей (id1, id2), либо любые hashable объекты.\n",
        "    \"\"\"\n",
        "    # Приведём к set для ускорения проверки принадлежности\n",
        "    set_true = set(tuple(sorted(pair)) for pair in true_pairs)\n",
        "    set_pred = set(tuple(sorted(pair)) for pair in predicted_pairs)\n",
        "    true_positive = len(set_true & set_pred)\n",
        "    if not true_pairs:\n",
        "        return 0.0\n",
        "    return true_positive / len(set_true)\n",
        "\n",
        "def get_candidates_with_min_recall(candidates, true_pairs, min_recall):\n",
        "    \"\"\"\n",
        "    Отбирает минимально необходимое число кандидатов для достижения min_recall.\n",
        "    candidates — список кортежей (id1, id2, ...), совместимых с true_pairs по формату.\n",
        "    true_pairs — список \"правильных\" пар (id1, id2).\n",
        "    min_recall — float, например, 0.7 (70%)\n",
        "    Возвращает: список выбранных кандидатов (той же структуры, что и во входе).\n",
        "    \"\"\"\n",
        "    selected_candidates = []\n",
        "    predicted_pairs = []  # Только первые 2 id, так как третье — список атрибутов\n",
        "    for candidate in candidates:\n",
        "        predicted_pair = tuple(sorted(candidate[:2]))  # ключ из (id1, id2)\n",
        "        selected_candidates.append(candidate)\n",
        "        predicted_pairs.append(predicted_pair)\n",
        "        current_recall = recall_at_k(true_pairs, predicted_pairs)\n",
        "        if current_recall >= min_recall:\n",
        "            break\n",
        "    return selected_candidates"
      ],
      "metadata": {
        "id": "D3OjYz7ilNii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Поэтому важно заранее выделять те пары, которые можно с высокой степенью уверенности считать точными матчами, и те, что требуют дополнительной проверки. **Бутстрепнутый реколл (LCB) позволяет нам не только повысить точность, но и оценость достоверность предсказаний с учётом возможных погрешностей.**\n",
        "\n"
      ],
      "metadata": {
        "id": "uQL6yqvRnQNv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bootstrapped Recall** — это оценка recall, полученная с использованием бутстреп-метода. Она позволяет получить распределение значений recall и оценить его статистическую значимость.\n",
        "\n",
        "**Lower Confidence Bound (LCB)** — это нижняя граница доверительного интервала. Она представляет собой наименьшее значение, которое с заданной вероятностью содержит истинное значение параметра.\n",
        "\n"
      ],
      "metadata": {
        "id": "W5Lzl_P3oJ7_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**bootstrap_recall**"
      ],
      "metadata": {
        "id": "DVwmWF9aoebr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def bootstrap_recall(true_pairs, predicted_pairs, n_bootstrap=1000, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Вычисляет бутстрепнутый реколл (Lower Confidence Bound, LCB) для заданных истинных и предсказанных пар.\n",
        "\n",
        "    Аргументы:\n",
        "    - true_pairs: список истинных пар.\n",
        "    - predicted_pairs: список предсказанных пар.\n",
        "    - n_bootstrap: количество итераций бутстрепа.\n",
        "    - alpha: уровень значимости для расчета LCB.\n",
        "\n",
        "    Возвращает:\n",
        "    - lower_bound: нижняя граница доверительного интервала реколла.\n",
        "    \"\"\"\n",
        "    recalls = []\n",
        "    random.seed(random_seed)\n",
        "\n",
        "    true_pairs_set = set(tuple(sorted(pair)) for pair in true_pairs)\n",
        "    pred_pairs_set = set(tuple(sorted(pair)) for pair in predicted_pairs)\n",
        "    n_true = len(true_pairs)\n",
        "\n",
        "    if n_true == 0:\n",
        "        return 0.0\n",
        "    true_pairs_list = list(true_pairs_set)\n",
        "\n",
        "    for _ in range(n_bootstrap):\n",
        "      sampled_true = [random.choice(true_pairs_list) for _ in range(n_true)]\n",
        "      n_found = sum(pair in pred_pairs_set for pair in sampled_true)\n",
        "      recall = n_true/n_found\n",
        "      recalls.append(recall)\n",
        "    recalls.sort()\n",
        "    rank = max(0, min(rank, n_bootstrap - 1))\n",
        "    lower_bound = recalls[rank]\n",
        "    return lower_bound"
      ],
      "metadata": {
        "id": "ZE80btQlohDa"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_pairs(true_pairs, predicted_pairs, n_bootstrap=1000, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Классифицирует предсказанные пары на две группы: \"точно мэтч\" (>0.95), \"на валидацию\" (>0.85, ≤0.95).\n",
        "    - true_pairs: список кортежей (id1, id2), настоящее совпадение.\n",
        "    - predicted_pairs: список кортежей (id1, id2), ваши предсказания.\n",
        "    Возвращает:\n",
        "    - matched_pairs: список пар >0.95\n",
        "    - validation_pairs: >0.85 и ≤0.95\n",
        "    \"\"\"\n",
        "    matched_pairs = []\n",
        "    validation_pairs = []\n",
        "    for pair in predicted_pairs:\n",
        "        lcb_recall = bootstrap_recall(true_pairs, [pair], n_bootstrap=n_bootstrap, alpha=alpha)\n",
        "        if lcb_recall > 0.95:\n",
        "            matched_pairs.append(pair)\n",
        "        elif lcb_recall > 0.85:\n",
        "            validation_pairs.append(pair)\n",
        "    return matched_pairs, validation_pairs"
      ],
      "metadata": {
        "id": "ePnAPoF_rztS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}